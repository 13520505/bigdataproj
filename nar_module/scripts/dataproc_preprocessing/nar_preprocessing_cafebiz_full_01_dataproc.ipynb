{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup (only required for the first run on the Spark cluster)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "input:  file  cafebiz_articles.csv, file log join with dbnews to have id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /data/tungtv/home/miniconda/envs/VGPU3/lib/python3.6/site-packages (0.24.2)\n",
      "Requirement already satisfied: python-dateutil>=2.5.0 in /data/tungtv/home/miniconda/envs/VGPU3/lib/python3.6/site-packages (from pandas) (2.8.0)\n",
      "Requirement already satisfied: numpy>=1.12.0 in /data/tungtv/home/miniconda/envs/VGPU3/lib/python3.6/site-packages (from pandas) (1.16.4)\n",
      "Requirement already satisfied: pytz>=2011k in /data/tungtv/home/miniconda/envs/VGPU3/lib/python3.6/site-packages (from pandas) (2019.1)\n",
      "Requirement already satisfied: six>=1.5 in /data/tungtv/home/miniconda/envs/VGPU3/lib/python3.6/site-packages (from python-dateutil>=2.5.0->pandas) (1.12.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_PATH = '/data/tungtv/Code/dataset/dataset_cafebiz_full//'\n",
    "#TODO: Upload this file (generated by the ACR module training) to GCS before calling spark script\n",
    "# !gsutil cp {ROOT_PATH}/adressa_articles.csv."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import datetime\n",
    "import hashlib\n",
    "import math\n",
    "import matplotlib\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "import pyspark\n",
    "import pyspark.sql.functions as F\n",
    "import pyspark.sql.types as T\n",
    "from pyspark import SparkContext,SparkConf,SQLContext\n",
    "from pyspark.sql import SparkSession\n",
    "# from pyspark.sql.functions import pandas_udf\n",
    "# from pyspark.sql.functions import PandasUDFType\n",
    "from pyspark.sql.functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .master('local[*]') \\\n",
    "    .appName('myAppName1') \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = spark.sparkContext\n",
    "sqlContext = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.0\n"
     ]
    }
   ],
   "source": [
    "print(spark.version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading articles pre-processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles_original_df = pd.read_csv('/data/tungtv/Code/dataset/dataset_cafebiz_full/cafebiz_articles.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'content', 'created_at_ts', 'teaser', 'domain', 'keywords',\n",
       "       'title', 'url', 'category0', 'persons', 'locations', 'text_highlights',\n",
       "       'id_encoded', 'category0_encoded', 'keywords_encoded',\n",
       "       'locations_encoded', 'persons_encoded'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articles_original_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1960"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articles_original_df['url'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1960"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_articles_urls_to_ids_dict = dict(articles_original_df[['url','id_encoded']].apply(lambda x: (x['url'], x['id_encoded']), axis=1).values)\n",
    "len(valid_articles_urls_to_ids_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading user interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#INTERACTIONS_PATH = 'gs://news_public_datasets4/adressa/one_week/*'\n",
    "#INTERACTIONS_PATH = 'three_month/20170101'\n",
    "\n",
    "DAYS_TO_LOAD_INTERACTIONS=17\n",
    "interaction_json_files = [os.path.join(ROOT_PATH, 'three_month/201701{:02d}'.format(day)) for day in range(1, DAYS_TO_LOAD_INTERACTIONS)]\n",
    "print('Loading interaction files: {}'.format(interaction_json_files))\n",
    "\n",
    "interactions_df = spark.read \\\n",
    "  .option(\"mode\", \"PERMISSIVE\") \\\n",
    "  .json(interaction_json_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_file_log = 'hdfs://10.5.36.95:9000/user/thanhpt/log_tos_pc/' \n",
    "interactions_df  = spark.read.parquet(path_file_log+\"2019-02-**\")\n",
    "interactions_df =  interactions_df.filter(col(\"domain\").isin(['cafebiz.vn']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- dt: string (nullable = true)\n",
      " |-- cookietime: string (nullable = true)\n",
      " |-- browser_code: integer (nullable = true)\n",
      " |-- browser_ver: string (nullable = true)\n",
      " |-- os_code: integer (nullable = true)\n",
      " |-- os_version: string (nullable = true)\n",
      " |-- ip: long (nullable = true)\n",
      " |-- loc_id: integer (nullable = true)\n",
      " |-- domain: string (nullable = true)\n",
      " |-- path: string (nullable = true)\n",
      " |-- referer: string (nullable = true)\n",
      " |-- guid: string (nullable = true)\n",
      " |-- pageloadId: string (nullable = true)\n",
      " |-- screen: string (nullable = true)\n",
      " |-- d_guid: string (nullable = true)\n",
      " |-- category: string (nullable = true)\n",
      " |-- utm_source: string (nullable = true)\n",
      " |-- utm_campaign: string (nullable = true)\n",
      " |-- utm_medium: string (nullable = true)\n",
      " |-- milis: long (nullable = true)\n",
      " |-- tos: long (nullable = true)\n",
      " |-- tor: long (nullable = true)\n",
      " |-- top: long (nullable = true)\n",
      " |-- scrollEnd: integer (nullable = true)\n",
      " |-- pageLoadTime: long (nullable = true)\n",
      " |-- lookUpTime: long (nullable = true)\n",
      " |-- connectionTime: long (nullable = true)\n",
      " |-- pageDownloadTime: long (nullable = true)\n",
      " |-- responseTime: long (nullable = true)\n",
      " |-- redirectTime: long (nullable = true)\n",
      " |-- scrollCounter: long (nullable = true)\n",
      " |-- mouseMoveCounter: long (nullable = true)\n",
      " |-- touchMoveCounter: long (nullable = true)\n",
      " |-- age: integer (nullable = true)\n",
      " |-- gender: integer (nullable = true)\n",
      " |-- devCode: string (nullable = true)\n",
      " |-- reqId: string (nullable = true)\n",
      " |-- ads_code: integer (nullable = true)\n",
      " |-- flash_ver: string (nullable = true)\n",
      " |-- jre: string (nullable = true)\n",
      " |-- sr: string (nullable = true)\n",
      " |-- sc: integer (nullable = true)\n",
      " |-- org_ip: string (nullable = true)\n",
      " |-- d_guid_create: long (nullable = true)\n",
      " |-- siteId: string (nullable = true)\n",
      " |-- channelId: string (nullable = true)\n",
      " |-- geo: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "interactions_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3708197"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interactions_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Retrives article id from its cannonical URL (because sometimes article ids in interactions do no match with articles tables, but cannonical URL do)\n",
    "def get_article_id_encoded_from_url(canonical_url):\n",
    "    if canonical_url in valid_articles_urls_to_ids_dict:\n",
    "        return valid_articles_urls_to_ids_dict[canonical_url]    \n",
    "    return None\n",
    "\n",
    "get_article_id_encoded_from_url_udf = F.udf(get_article_id_encoded_from_url, pyspark.sql.types.IntegerType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filtering only interactions whose url/id is available in the articles table\n",
    "interactions_article_id_encoded_df = interactions_df.withColumn('article_id', get_article_id_encoded_from_url_udf(interactions_df['canonicalUrl']))\n",
    "interactions_filtered_df = interactions_article_id_encoded_df.filter(interactions_article_id_encoded_df['article_id'].isNull() == False).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# interactions_filtered_df.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5517760"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Valid interactions\n",
    "interactions_filtered_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26909"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Distinct items count\n",
    "interactions_filtered_df.select('article_id').distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modified\n",
    "# interactions_filtered_df.type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1483225202000"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_timestamp_ts = interactions_filtered_df.select('time').agg(F.min('time')).collect()[0][0] * 1000\n",
    "first_timestamp_ts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyzing elapsed time since publishing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#interactions_filtered_df.filter(interactions_filtered_df['time'].isNull()).count()\n",
    "#0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_timestamp_from_date_str(value):\n",
    "    if value is not None:\n",
    "        return int(datetime.datetime.strptime(value, '%Y-%m-%dT%H:%M:%S.%fZ').timestamp())\n",
    "    return None\n",
    "\n",
    "get_timestamp_from_date_str_udf = F.udf(get_timestamp_from_date_str, pyspark.sql.types.IntegerType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "interactions_filtered_with_publish_ts_df = interactions_filtered_df.withColumn('publish_ts', get_timestamp_from_date_str_udf(interactions_filtered_df['publishtime']))\n",
    "interactions_filtered_with_publish_ts_df = interactions_filtered_with_publish_ts_df.withColumn('elapsed_min_since_published', ((F.col('time') - F.col('publish_ts')) / 60).cast(pyspark.sql.types.IntegerType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#interactions_filtered_with_publish_ts_df.select('publishtime','publish_ts', 'time', 'elapsed_min_since_published').show(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 16 ms, sys: 22.8 ms, total: 38.8 ms\n",
      "Wall time: 6.89 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[467.0, 533.0, 727.0, 1565.0, 3105.0]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "interactions_filtered_with_publish_ts_df.approxQuantile(\"elapsed_min_since_published\", [0.10, 0.25, 0.50, 0.75, 0.90], 0.01)\n",
    "#[49.0, 108.0, 334.0, 1020.0, 4611.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79409\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>elapsed_min_since_published</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5.438351e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>7.857292e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>5.645131e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-3.147390e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>5.180000e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>7.140000e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.360000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.144763e+07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       elapsed_min_since_published\n",
       "count                 5.438351e+06\n",
       "mean                  7.857292e+04\n",
       "std                   5.645131e+05\n",
       "min                  -3.147390e+05\n",
       "25%                   5.180000e+02\n",
       "50%                   7.140000e+02\n",
       "75%                   1.360000e+03\n",
       "max                   1.144763e+07"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elapsed_min_since_published_df = interactions_filtered_with_publish_ts_df.select('elapsed_min_since_published').toPandas()\n",
    "print(len(elapsed_min_since_published_df[pd.isnull(elapsed_min_since_published_df['elapsed_min_since_published'])]))\n",
    "elapsed_min_since_published_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nelapsed_min_since_published\\ncount\\t2.600818e+06\\nmean\\t6.438622e+04\\nstd\\t5.051825e+05\\nmin\\t-3.151590e+05\\n25%\\t9.400000e+01\\n50%\\t2.580000e+02\\n75%\\t8.370000e+02\\nmax\\t8.608278e+06\\n'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "'''\n",
    "elapsed_min_since_published\n",
    "count\t2.600818e+06\n",
    "mean\t6.438622e+04\n",
    "std\t5.051825e+05\n",
    "min\t-3.151590e+05\n",
    "25%\t9.400000e+01\n",
    "50%\t2.580000e+02\n",
    "75%\t8.370000e+02\n",
    "max\t8.608278e+06\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyzing clicks by article distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clicks_by_article_count_df = interactions_filtered_df.groupBy('article_id').count()\n",
    "#clicks_by_article_count_df.approxQuantile(\"count\", [0.01, 0.10, 0.25, 0.50, 0.75, 0.90, 0.99], 0.01)\n",
    "#[1.0, 1.0, 1.0, 1.0, 2.0, 6.0, 33581.0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_categ_features_counts_dataframe(interactions_spark_df,column_name):\n",
    "    df_pandas = interactions_spark_df.groupBy(column_name).count().toPandas().sort_values('count', ascending=False)\n",
    "    return df_pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "PAD_TOKEN = '<PAD>'\n",
    "UNFREQ_TOKEN = '<UNF>'\n",
    "\n",
    "def get_encoder_for_values(values):\n",
    "    encoder_values = [PAD_TOKEN, UNFREQ_TOKEN] + values\n",
    "    encoder_ids = list(range(len(encoder_values)))\n",
    "    encoder_dict = dict(zip(encoder_values, encoder_ids))\n",
    "    return encoder_dict\n",
    "\n",
    "def get_categ_features_encoder_dict(counts_df, min_freq=100):\n",
    "    freq_values = counts_df[counts_df['count'] >= 100][counts_df.columns[0]].values.tolist()\n",
    "    encoder_dict = get_encoder_for_values(freq_values)\n",
    "    return encoder_dict\n",
    "\n",
    "def encode_cat_feature(value, encoder_dict):\n",
    "    if value in encoder_dict:\n",
    "        return encoder_dict[value]\n",
    "    else:\n",
    "        return encoder_dict[UNFREQ_TOKEN]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "178"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "countries_df = get_categ_features_counts_dataframe(interactions_filtered_df, 'country')\n",
    "len(countries_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "countries_encoder_dict = get_categ_features_encoder_dict(countries_df)\n",
    "len(countries_encoder_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7012"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cities_df = get_categ_features_counts_dataframe(interactions_filtered_df, 'city')\n",
    "len(cities_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1025"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cities_encoder_dict = get_categ_features_encoder_dict(cities_df)\n",
    "len(cities_encoder_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1354"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regions_df = get_categ_features_counts_dataframe(interactions_filtered_df, 'region')\n",
    "len(regions_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "238"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regions_encoder_dict = get_categ_features_encoder_dict(regions_df)\n",
    "len(regions_encoder_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>deviceType</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mobile</td>\n",
       "      <td>2682837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Desktop</td>\n",
       "      <td>1726706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tablet</td>\n",
       "      <td>1108217</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  deviceType    count\n",
       "0     Mobile  2682837\n",
       "2    Desktop  1726706\n",
       "1     Tablet  1108217"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "devices_df = get_categ_features_counts_dataframe(interactions_filtered_df, 'deviceType')\n",
    "print(len(devices_df))\n",
    "devices_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "devices_encoder_dict = get_categ_features_encoder_dict(devices_df)\n",
    "len(devices_encoder_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>os</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>iPhone OS</td>\n",
       "      <td>2364480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Windows</td>\n",
       "      <td>1469623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Android</td>\n",
       "      <td>1405860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Macintosh</td>\n",
       "      <td>236950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Windows Phone OS</td>\n",
       "      <td>18761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Linux</td>\n",
       "      <td>15389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Unknown</td>\n",
       "      <td>6342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BlackBerry</td>\n",
       "      <td>288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Symbian OS</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>BSD</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SunOS</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  os    count\n",
       "0          iPhone OS  2364480\n",
       "10           Windows  1469623\n",
       "8            Android  1405860\n",
       "3          Macintosh   236950\n",
       "2   Windows Phone OS    18761\n",
       "5              Linux    15389\n",
       "7            Unknown     6342\n",
       "4         BlackBerry      288\n",
       "1         Symbian OS       43\n",
       "9                BSD       14\n",
       "6              SunOS       10"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os_df = get_categ_features_counts_dataframe(interactions_filtered_df, 'os')\n",
    "print(len(os_df))\n",
    "os_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os_encoder_dict = get_categ_features_encoder_dict(os_df)\n",
    "len(os_encoder_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>referrerHostClass</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>internal</td>\n",
       "      <td>3277921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>search</td>\n",
       "      <td>782901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>direct</td>\n",
       "      <td>779496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>social</td>\n",
       "      <td>423573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>other</td>\n",
       "      <td>253869</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  referrerHostClass    count\n",
       "2          internal  3277921\n",
       "4            search   782901\n",
       "0            direct   779496\n",
       "3            social   423573\n",
       "1             other   253869"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "referrer_class_df = get_categ_features_counts_dataframe(interactions_filtered_df, 'referrerHostClass')\n",
    "print(len(referrer_class_df))\n",
    "referrer_class_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "referrer_class_encoder_dict = get_categ_features_encoder_dict(referrer_class_df)\n",
    "len(referrer_class_encoder_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoders_dict = {\n",
    "    'city': cities_encoder_dict,\n",
    "    'region': regions_encoder_dict,\n",
    "    'country': countries_encoder_dict,\n",
    "    'os': os_encoder_dict,\n",
    "    'device': devices_encoder_dict,\n",
    "    'referrer_class': referrer_class_encoder_dict\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing numeric features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8.0, 19.0, 45.0, 90.0, 147.0]\n",
      "CPU times: user 24.8 ms, sys: 19.2 ms, total: 44 ms\n",
      "Wall time: 1.22 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "active_time_quantiles = interactions_filtered_df.approxQuantile(\"activeTime\", [0.10, 0.25, 0.50, 0.75, 0.90], 0.01)\n",
    "print(active_time_quantiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>summary</th>\n",
       "      <th>activeTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>count</td>\n",
       "      <td>2336917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mean</td>\n",
       "      <td>65.07003072851967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>stddev</td>\n",
       "      <td>69.32856559320139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>min</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>max</td>\n",
       "      <td>899</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  summary         activeTime\n",
       "0   count            2336917\n",
       "1    mean  65.07003072851967\n",
       "2  stddev  69.32856559320139\n",
       "3     min                  1\n",
       "4     max                899"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "active_time_stats_df = interactions_filtered_df.describe('activeTime').toPandas()\n",
    "active_time_stats_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "active_time_mean = float(active_time_stats_df[active_time_stats_df['summary'] == 'mean']['activeTime'].values[0])\n",
    "active_time_stddev = float(active_time_stats_df[active_time_stats_df['summary'] == 'stddev']['activeTime'].values[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nschema = T.StructType([\\n    T.StructField(\"userId\", T.StringType()),\\n    T.StructField(\"min_ts\", T.IntegerType())\\n])\\n\\n@pandas_udf(schema, functionType=PandasUDFType.GROUPED_MAP)\\ndef split_sessions(df):\\n\\n    result_df = df[[\\'userId\\']]\\n    result_df[\\'min_ts\\'] = df[\\'time\\'].min()\\n    \\n    return result\\n\\n%%time\\ntmp = interactions_filtered_df.groupBy(\\'userId\\').apply(split_sessions)\\ntmp.show(100)\\n'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "schema = T.StructType([\n",
    "    T.StructField(\"userId\", T.StringType()),\n",
    "    T.StructField(\"min_ts\", T.IntegerType())\n",
    "])\n",
    "\n",
    "@pandas_udf(schema, functionType=PandasUDFType.GROUPED_MAP)\n",
    "def split_sessions(df):\n",
    "\n",
    "    result_df = df[['userId']]\n",
    "    result_df['min_ts'] = df['time'].min()\n",
    "    \n",
    "    return result\n",
    "\n",
    "%%time\n",
    "tmp = interactions_filtered_df.groupBy('userId').apply(split_sessions)\n",
    "tmp.show(100)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hash_str_to_int(encoded_bytes_text, digits):\n",
    "    return int(str(int(hashlib.md5(encoded_bytes_text).hexdigest()[:8], 16))[:digits])      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SESSION_IDLE_TIME_MS = 30 * 60 * 1000    #30 min\n",
    "\n",
    "def close_session(session):\n",
    "    size = len(session)\n",
    "    \n",
    "    #Creating and artificial session id based on the first click timestamp and a hash of user id\n",
    "    first_click = session[0]\n",
    "    session_id = (int(first_click['timestamp']) * 100) + hash_str_to_int(first_click['user_id'].encode(), 3)\n",
    "    session_hour = int((first_click['timestamp'] - first_timestamp_ts) / (1000 * 60 * 60)) #Converting timestamp to hours since first timestamp\n",
    "    \n",
    "    #Converting to Spark DataFrame Rows, to convert RDD back to DataFrame\n",
    "    clicks = list([T.Row(**click) for click in session])\n",
    "    session_dict = {'session_id': session_id,\n",
    "                    'session_hour': session_hour,\n",
    "                    'session_size': size,\n",
    "                    'session_start': first_click['timestamp'],\n",
    "                    'user_id': first_click['user_id'],\n",
    "                    'clicks': clicks \n",
    "                   }\n",
    "    session_row = T.Row(**session_dict)\n",
    "    \n",
    "    return session_row\n",
    "        \n",
    "def transform_interaction(interaction):        \n",
    "    return {\n",
    "            'article_id': interaction['article_id'],\n",
    "            'url': interaction['canonicalUrl'],\n",
    "            'user_id': interaction['userId'],\n",
    "            'timestamp': interaction['time'] * 1000, #converting to timestamp\n",
    "            'active_time_secs': interaction['activeTime'],\n",
    "            'country': encode_cat_feature(interaction['country'], encoders_dict['country']),\n",
    "            'region': encode_cat_feature(interaction['region'], encoders_dict['region']),\n",
    "            'city': encode_cat_feature(interaction['city'], encoders_dict['city']),\n",
    "            'os': encode_cat_feature(interaction['os'], encoders_dict['os']),\n",
    "            'device': encode_cat_feature(interaction['deviceType'], encoders_dict['device']),\n",
    "            'referrer_class': encode_cat_feature(interaction['referrerHostClass'], encoders_dict['referrer_class']),\n",
    "           }\n",
    "\n",
    "def split_sessions(group):\n",
    "    user, interactions = group\n",
    "    #Ensuring items are sorted by time\n",
    "    interactions_sorted_by_time = sorted(interactions, key=lambda x: x['time'])\n",
    "    #Transforming interactions\n",
    "    interactions_transformed = list(map(transform_interaction, interactions_sorted_by_time))\n",
    "\n",
    "    \n",
    "    sessions = []\n",
    "    session = []        \n",
    "    first_timestamp = interactions_transformed[0]['timestamp']\n",
    "    last_timestamp = first_timestamp    \n",
    "    for interaction in interactions_transformed:\n",
    "        \n",
    "        delta_ms = (interaction['timestamp'] - last_timestamp)\n",
    "        interaction['_elapsed_ms_since_last_click'] = delta_ms \n",
    "\n",
    "        if delta_ms <= MAX_SESSION_IDLE_TIME_MS:    \n",
    "            #Ignoring repeated items in session\n",
    "            if len(list(filter(lambda x: x['article_id'] == interaction['article_id'], session))) == 0:        \n",
    "                session.append(interaction)            \n",
    "        else:\n",
    "            #If session have at least 2 clicks (minimum for next click predicition)\n",
    "            if len(session) >= 2:\n",
    "                session_row = close_session(session)\n",
    "                sessions.append(session_row)                \n",
    "            session = [interaction]\n",
    "\n",
    "        last_timestamp = interaction['timestamp']\n",
    "            \n",
    "    if len(session) >= 2:\n",
    "        session_row = close_session(session)\n",
    "        sessions.append(session_row)\n",
    "        \n",
    "    #if len(sessions) > 1:\n",
    "    #    raise Exception('USER with more than one session: {}'.format(user))\n",
    "    \n",
    "    return list(zip(map(lambda x: x['session_id'], sessions), \n",
    "                    sessions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n#To debug\\n%%time\\nsessions_rdd = interactions_filtered_df.limit(1000).rdd.map(lambda x: (x['userId'], x)).groupByKey()                     .collect()\\n\\nfor row in sessions_rdd:\\n    print(split_sessions(row))\\n    print()\\n\""
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "#To debug\n",
    "%%time\n",
    "sessions_rdd = interactions_filtered_df.limit(1000).rdd.map(lambda x: (x['userId'], x)).groupByKey() \\\n",
    "                    .collect()\n",
    "\n",
    "for row in sessions_rdd:\n",
    "    print(split_sessions(row))\n",
    "    print()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 558 ms, sys: 142 ms, total: 700 ms\n",
      "Wall time: 16min 42s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "sessions_rdd = interactions_filtered_df.rdd.map(lambda x: (x['userId'], x)).groupByKey() \\\n",
    "                            .flatMap(split_sessions) \\\n",
    "                            .sortByKey() \\\n",
    "                            .map(lambda x: x[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exporting sessions to JSON lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "sessions_sdf = sessions_rdd.toDF()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 20.4 ms, sys: 15 ms, total: 35.4 ms\n",
      "Wall time: 4.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "sessions_sdf.write.partitionBy(\"session_hour\").json(os.path.join(ROOT_PATH,\"data_transformed/sessions_processed_by_spark/\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "989276"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sessions_sdf.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def serialize(filename, obj):\n",
    "    with open(filename, 'wb') as handle:\n",
    "        pickle.dump(obj, handle)#, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "NAR_ENCODERS_PATH  = 'nar_encoders_adressa.pickle'\n",
    "serialize(NAR_ENCODERS_PATH, encoders_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp {NAR_ENCODERS_PATH} {ROOT_PATH}/data_transformed/pickles/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
